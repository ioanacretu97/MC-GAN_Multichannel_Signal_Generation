{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2f1e17",
   "metadata": {},
   "source": [
    "# 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training the GAN \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import autograd\n",
    "\n",
    "%run ./model.ipynb\n",
    "%run ./utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(ECG, BP, CVP, patients_baseline, labels, fs=1000):\n",
    "    VEs_45 = [512,1434,2798,4168,5544,7403,9271,11129,12030,12927,13816,14725,16116,17970,19363,21214]\n",
    "    VEs_34_11 = [1907, 3695,4364,7696] \n",
    "    VEs_34_12 = [443,1118,1800] \n",
    "    VEs_34_13 = [1501,2171,2844,4412,6418, 6728,7994]\n",
    "    VEs_26 = [1472,2120, 6964, 7216] \n",
    "    \n",
    "    segmented_ecg = []\n",
    "    segmented_bp = []\n",
    "    segmented_cvp = []\n",
    "    signals_labels = []\n",
    "    patients_labels = []\n",
    "    \n",
    "#     before = 400\n",
    "#     after = 400\n",
    "    for i in range(0,len(ECG)):\n",
    "        ecg_signal = np.array(ECG[i])       \n",
    "        bp_signal = np.array(BP[i])\n",
    "        cvp_signal = np.array(CVP[i])\n",
    "        \n",
    "        if labels[i] == 'A-tach 2:1 block':\n",
    "            r_peaks,freq = scipy.signal.find_peaks(ecg_signal, height= 0.08*np.max(ecg_signal), distance=135)\n",
    "        else:\n",
    "            r_peaks, freq = scipy.signal.find_peaks(-ecg_signal, height =np.mean(ecg_signal)+np.std(ecg_signal), distance=120)\n",
    "      \n",
    "        \n",
    "        for j in range(0,len(r_peaks)):\n",
    "            if  r_peaks[j]-400>0 and r_peaks[j]+400<len(ecg_signal) and r_peaks[j]+600<len(bp_signal):\n",
    "                segmented_ecg.append(ecg_signal[r_peaks[j]-400:r_peaks[j]+400])\n",
    "                segmented_bp.append(bp_signal[r_peaks[j]-200:r_peaks[j]+600]) \n",
    "                segmented_cvp.append(cvp_signal[r_peaks[j]-200:r_peaks[j]+600])\n",
    "\n",
    "                patients_labels.append(patients_baseline[i])\n",
    "                \n",
    "                if patients_baseline[i]==34 and i==11 and r_peaks[j] in VEs_34_11:\n",
    "                    signals_labels.append('SR with VEs')\n",
    "                elif patients_baseline[i]==34 and i==12 and r_peaks[j] in VEs_34_12:\n",
    "                    signals_labels.append('SR with VEs')\n",
    "                elif patients_baseline[i]==34 and i==13 and r_peaks[j] in VEs_34_13:\n",
    "                    signals_labels.append('SR with VEs')\n",
    "                elif patients_baseline[i]==45 and r_peaks[j] in VEs_45:\n",
    "                    signals_labels.append('SR with VEs')  \n",
    "                elif (patients_baseline[i]==45 or patients_baseline[i]==34) and r_peaks[j] not in VEs_45 and r_peaks[j] not in VEs_34_11 and r_peaks[j] not in VEs_34_12 and r_peaks[j] not in VEs_34_13:\n",
    "                    signals_labels.append('SR') \n",
    "                elif patients_baseline[i]==26 and r_peaks[j] in VEs_26:\n",
    "                    signals_labels.append('paced')\n",
    "                else:\n",
    "                    signals_labels.append(labels[i])            \n",
    "\n",
    "    items = [x for x in enumerate(signals_labels) if 'SR with VEs' in x]\n",
    "    for k in range(len(items)):\n",
    "        signals_labels[items[k][0]-1] = 'SR with VEs'\n",
    "        signals_labels[items[k][0]+1] = 'SR with VEs'\n",
    "    \n",
    "    return segmented_ecg, segmented_bp, segmented_cvp, signals_labels,patients_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a2f6d",
   "metadata": {},
   "source": [
    "# 2. Read the baseline signals from all the patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435bc478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path and patients numbers \n",
    "path_root = 'D:/WGAN CODE- FROM SERVER FINAL/Datasets/Harefield/'\n",
    "patients = ['P09','P10','P11','P12','P25','P26','P31','P33','P34','P35','P37','P38','P39','P44', \n",
    "            'P45','P46','P47','P51','P52','P53', 'P88', '100','101','102']\n",
    "\n",
    "# Select which signals you want to extract\n",
    "baseline =['baseline','intrinsic','underlying','ULR']  \n",
    "\n",
    "# Get all the paths for the baseline signals\n",
    "baseline_files = get_files(path_root, patients,baseline) \n",
    "\n",
    "# Read and store all the ecg signals into both a df and a list\n",
    "[BP,patients_baseline] = read_data(baseline_files,'/bp_dist.txt')\n",
    "[ECG,_] = read_data(baseline_files,'/ecg.txt')\n",
    "[CVP,_] = read_data(baseline_files,'/bp_prox.txt')\n",
    "\n",
    "[BP, CVP] =calibrate_signals(BP, CVP, scale_factor_BP=40, scale_factor_CVP=8)\n",
    "\n",
    "# Read the details of the patients in here:\n",
    "dataset_details = pd.read_csv('D:/WGAN CODE- FROM SERVER FINAL/Datasets/Harefield//PACESIM patients anonymised - Pacemaker patients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47514054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract labels from dataframe\n",
    "labels_signals = []\n",
    "for i in range(len(patients_baseline)):\n",
    "    for j in range(len(dataset_details['Pacesim ID'])):\n",
    "        if patients_baseline[i] == int(re.findall(r'\\d+',dataset_details['Pacesim ID'][j])[0]):\n",
    "            labels_signals.append(dataset_details['ULR'][j])\n",
    "            \n",
    "details_df = dict()\n",
    "details_df['Patient'] = patients_baseline\n",
    "details_df['labels'] = labels_signals\n",
    "details_df = pd.DataFrame(details_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=-1\n",
    "\n",
    "fs = 1000\n",
    "t = np.linspace(0, (len(ECG[x][:10000])-1)*(1/fs), len(ECG[x][:10000]))\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# Subplot for ECG\n",
    "plt.subplot(311)\n",
    "plt.plot(t, ECG[x][:10000])\n",
    "plt.ylabel('ECG (mV)', fontsize=16, labelpad=10)  # Increase label padding\n",
    "plt.margins(x=0)\n",
    "\n",
    "# Subplot for ABP\n",
    "plt.subplot(312)\n",
    "plt.plot(t, BP[x][:10000])\n",
    "plt.ylabel('ABP (mmHG)', fontsize=16, labelpad=15)  # Match label padding\n",
    "plt.margins(x=0)\n",
    "\n",
    "# Subplot for CVP\n",
    "plt.subplot(313)\n",
    "plt.plot(t, CVP[x][:10000])\n",
    "plt.ylabel('CVP (mmHG)', fontsize=16, labelpad=25)  # Match label padding\n",
    "plt.xlabel('Time (s)', fontsize=16)\n",
    "plt.margins(x=0)\n",
    "\n",
    "# Adjust the layout to align y-labels\n",
    "plt.subplots_adjust(left=0.2, right=0.95, top=0.95, bottom=0.1, hspace=0.4)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down-sample the signals to 200 datapoints (initial length=800)\n",
    "# BP = down_sample(BP)\n",
    "# ECG = down_sample(ECG)\n",
    "\n",
    "[ECG_denoised, patients_baseline,labels_signals] = cut_noise(ECG,patients_baseline,labels_signals)\n",
    "[BP_denoised, _, _] = cut_noise(BP,patients_baseline,labels_signals)\n",
    "[CVP_denoised, _, _] = cut_noise(CVP,patients_baseline,labels_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf503e",
   "metadata": {},
   "source": [
    "# 3. Segment the signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cd593",
   "metadata": {},
   "outputs": [],
   "source": [
    "[segmented_ecg, segmented_bp, segmented_cvp, labels_beats, patients_labels] = segmentation(ECG_denoised, BP_denoised,CVP_denoised, patients_baseline,labels_signals) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_labels = [i for i in range(len(labels_beats)) if labels_beats[i]==\"SR with VEs\" or labels_beats[i]==\"SR\" or labels_beats[i]==\"SR with LBBB\" or labels_beats[i]==\"A-tach 2:1 block\" or labels_beats[i]==\"AF\"]\n",
    "segmented_ecg = [segmented_ecg[i] for i in selected_labels]\n",
    "segmented_bp = [segmented_bp[i] for i in selected_labels] \n",
    "segmented_cvp = [segmented_cvp[i] for i in selected_labels] \n",
    "\n",
    "labels_beats = [labels_beats[i] for i in selected_labels] \n",
    "patients_labels = [patients_labels[i] for i in selected_labels] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9db18b",
   "metadata": {},
   "source": [
    "# 4. Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c746a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_beats =  np.array(labels_beats)\n",
    "unique, counts = np.unique(labels_beats, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d2b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc_data = enc.fit_transform(labels_beats).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71254ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, enc.classes_ will give you the original label for each encoded value\n",
    "print(\"Encoded values and their original labels:\")\n",
    "for encoded_value, original_label in enumerate(enc.classes_):\n",
    "    print(f\"{encoded_value} -> {original_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089d997",
   "metadata": {},
   "source": [
    "# 5. Normalise signals between [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbb108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise beats between -1 and 1\n",
    "segmented_ecg = normalise(segmented_ecg ,-1, 1)\n",
    "segmented_bp = normalise(segmented_bp, -1, 1)\n",
    "segmented_cvp = normalise(segmented_cvp, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64bd45d",
   "metadata": {},
   "source": [
    "# 6. stack signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b575082",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = [np.stack((segmented_ecg[i], segmented_bp[i], segmented_cvp[i]), axis=0) for i in range(0,len(segmented_bp))]\n",
    "train_data =[([signals[i], enc_data[i]]) for i in range(len(signals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.array(signals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c52f4a6",
   "metadata": {},
   "source": [
    "# 7. Set up the WGAN hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./last_model.ipynb\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "#wandb.login()\n",
    "os.environ[\"WANDB_API_KEY\"] = 'b8b8e375fa11f69790bff448e326c90a5435494b'\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the random seed for PyTorch (CPU)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# If using GPU, set the random seed for CUDA as well\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "channels_signal = 3\n",
    "latent_dim = np.shape(np.array(signals))[2]\n",
    "generator_layers = 6\n",
    "\n",
    "batch_size = 16\n",
    "discriminator_updates = 5\n",
    "num_epochs = 1000\n",
    "\n",
    "num_classes = len(unique)\n",
    "embed_size = np.shape(np.array(signals))[2]\n",
    "signal_length = np.shape(np.array(signals))[2]\n",
    "\n",
    "LAMBDA_GP = 10\n",
    "no_of_batches = len(signals)/batch_size \n",
    "batches_per_epoch = round(len(signals)/batch_size)\n",
    "\n",
    "gen_name = f\"Gen_baseline_all_{num_epochs}_3C\"\n",
    "disc_name = f\"Disc_baseline_all_{num_epochs}_3C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters \n",
    "# channels_signal = 2\n",
    "# latent_dim = 750\n",
    "# generator_layers = 5\n",
    "\n",
    "# lr = 0.0001\n",
    "# batch_size = 8\n",
    "# discriminator_updates = 5\n",
    "# num_epochs = 2000\n",
    "\n",
    "# num_classes = 4\n",
    "# embed_size = 750\n",
    "# signal_length = 750\n",
    "\n",
    "# LAMBDA_GP = 10\n",
    "# no_of_batches = len(ECG_BP)/batch_size \n",
    "# batches_per_epoch = round(len(ECG_BP)/batch_size)\n",
    "\n",
    "# gen_name = \"Gen2000_4classes\"\n",
    "# disc_name = \"Disc2000_4classes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture a dictionary of hyperparameters with config\n",
    "device =  \"cuda\" #if torch.cuda.is_available() \n",
    "config = {\"learning_rate_critic\": 0.00001, \n",
    "          \"learning_rate_generator\": 0.00001, #0.00005 ,\n",
    "          \"epochs\": num_epochs,\n",
    "          \"Channels\": channels_signal,\n",
    "          \"architecture\": \"connections_instancenorm\",\n",
    "          \"dropout\":\"none\",\n",
    "          \"machine\": \"GPU_server\",\n",
    "          \"batch_size\": batch_size, \n",
    "          \"generator_layers\": generator_layers, \n",
    "          \"discriminator_updates\":discriminator_updates,\n",
    "          \"LAMBDA_GP\":LAMBDA_GP, \n",
    "          \"Optimizer\":'Adam+betas0and0.9', \n",
    "          \"Generator\":'UNet1D', \n",
    "          \"Discriminator\":'CNN', \n",
    "          \"data\": \"all_baseline_data:SR_AF_tah_VEs\",\n",
    "          \"type_GAN\":'CGAN', \n",
    "          \"classes\":unique,\n",
    "          \"gen_name\": gen_name,\n",
    "          \"disc_name\": disc_name\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78b7ca",
   "metadata": {},
   "source": [
    "# 8. Train the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f508d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with wandb.init(project='WGAN_baseline', entity='ioanacretu', config=config):\n",
    "        config = wandb.config\n",
    "        #dataloader = DataLoader(ECG_BP,batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
    "        trainloader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, drop_last=True)\n",
    "            \n",
    "        # Create discriminator and generator\n",
    "        critic = CNN_Discriminator(num_classes, signal_length).to(device) \n",
    "        generator = UNet1D(2, 2, num_classes,embed_size, n_layers =config.generator_layers).to(device)\n",
    "        \n",
    "        initialize_weights(critic)\n",
    "        initialize_weights(generator)\n",
    "        \n",
    "        # Set up Optimizer for G and D\n",
    "        optimizer_critic =  optim.Adam(critic.parameters(), lr=config.learning_rate, betas=(0, 0.9))\n",
    "        optimizer_generator = optim.Adam(generator.parameters(),lr=config.learning_rate, betas=(0, 0.9))\n",
    "        \n",
    "        # Watch weights and gradients for both critic and generator\n",
    "        wandb.watch(critic, log=\"all\")\n",
    "        wandb.watch(generator, log=\"all\")\n",
    "\n",
    "        generator.train()\n",
    "        critic.train()\n",
    "\n",
    "        #fixed_noise = torch.randn(batch_size,latent_dim,1).to(device)\n",
    "        fixed_noise = torch.randn(config.batch_size,2,latent_dim).uniform_(-1, 1).to(device)\n",
    "        critic_iter = 0\n",
    "        gen_iter = 0\n",
    "\n",
    "        print(\"Starting training...\")\n",
    "        for epoch in range(config.epochs):\n",
    "            print(epoch)\n",
    "            wandb.log({\"Epoch\":epoch})\n",
    "            for batch_idx, (data,labels) in enumerate(trainloader):\n",
    "                data = data.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                data = data.float()  #solved error \"Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same\"\n",
    "        \n",
    "                # Train the Critic/Discriminator: max E[critic(real)] - E[critic(fake)]\n",
    "                for _ in range(config.discriminator_updates):\n",
    "                    critic_iter = critic_iter +1\n",
    "                    #noise = torch.randn(config.batch_size,latent_dim,1).uniform_(-1, 1).to(device)\n",
    "                    noise = torch.randn(config.batch_size,2,latent_dim).uniform_(-1, 1).to(device)\n",
    "                    fake = generator(noise,labels)\n",
    "\n",
    "                    critic_real = critic(data,labels).reshape(-1)\n",
    "                    critic_fake = critic(fake,labels).reshape(-1) #here we changed according to github repo alladin, it was before critic_fake = critic(fake.detach(),labels).reshape(-1)\n",
    "                    \n",
    "                    gp = gradient_penalty(critic,labels, data, fake, device = device)\n",
    "                    loss_critic =(-(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp)\n",
    "\n",
    "                    critic.zero_grad()\n",
    "                    loss_critic.backward(retain_graph=True)\n",
    "                    optimizer_critic.step()\n",
    "                    \n",
    "               ## clear memory after a no of steps: is it enought to keep the w. for disc_updates steps? ##loss_critic.backward(retain_graph=False)\n",
    "    \n",
    "                # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
    "                gen_iter = gen_iter + 1\n",
    "                gen_fake = critic(fake,labels).reshape(-1)\n",
    "                loss_generator = -torch.mean(gen_fake)\n",
    "                \n",
    "                wandb.log({\"Critic_iteration\": critic_iter, \"Critic_loss\": loss_critic})\n",
    "                wandb.log({\"Generator_iteration\": gen_iter, \"Generator_loss\": loss_generator})\n",
    "        \n",
    "                generator.zero_grad()\n",
    "                loss_generator.backward()\n",
    "                optimizer_generator.step()\n",
    "               \n",
    "            with torch.no_grad():\n",
    "                generated_signals = generator(fixed_noise,labels)\n",
    "                gener = generated_signals.cpu().detach().numpy()\n",
    "                plt.subplot(211)\n",
    "                plt.plot(gener[0][0])\n",
    "                plt.title('electrocardiogram')\n",
    "                plt.subplot(212)\n",
    "                plt.plot(gener[0][1])\n",
    "                plt.title('arterial line blood pressure')\n",
    "                wandb.log({'chart': plt})\n",
    "                \n",
    "            print(f\"Critic loss is:{loss_critic}\")\n",
    "            print(f\"Gen loss is:{loss_generator}\")\n",
    "            print(\"----------------------------------\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project='WGAN_baseline', entity='ioanacretu', config=config):\n",
    "    config = wandb.config\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    #dataloader = DataLoader(ECG_BP,batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
    "    trainloader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    # Create discriminator and generator\n",
    "    critic = CNN_Discriminator(num_classes, signal_length, num_channels=channels_signal).to(device) \n",
    "    generator = UNet1D(channels_signal, channels_signal, num_classes, embed_size, n_layers=config.generator_layers).to(device)\n",
    "\n",
    "    initialize_weights(critic)\n",
    "    initialize_weights(generator)\n",
    "\n",
    "    # Set up Optimizer for G and D\n",
    "    optimizer_critic =  optim.Adam(critic.parameters(), lr=config.learning_rate_critic, betas=(0, 0.9))\n",
    "    optimizer_generator = optim.Adam(generator.parameters(), lr=config.learning_rate_generator, betas=(0, 0.9))\n",
    "\n",
    "#         optimizer_critic =  optim.Adam(critic.parameters(), lr=config.learning_rate, betas=(0, 0.9))\n",
    "#         optimizer_generator = optim.Adam(generator.parameters(),lr=config.learning_rate, betas=(0, 0.9))\n",
    "\n",
    "    # Watch weights and gradients for both critic and generator\n",
    "    wandb.watch(critic, log=\"all\")\n",
    "    wandb.watch(generator, log=\"all\")\n",
    "\n",
    "    #fixed_noise = torch.randn(batch_size,latent_dim,1).to(device)\n",
    "    fixed_noise = torch.randn(config.batch_size,channels_signal,latent_dim).uniform_(-1, 1).to(device)\n",
    "    fixed_labels = torch.randint(low=0, high=num_classes, size=(config.batch_size,)).to(device)\n",
    "\n",
    "#         if wandb.run.resumed:\n",
    "#             checkpoint_filename_disc = f\"\\disc_APVP_AVD200_epoch{epoch + 1}.pth\"\n",
    "#             checkpoint_filename_gen = f\"\\gen_APVP_AVD200_epoch{epoch + 1}.pth\"\n",
    "#             checkpoint_path_disc = \n",
    "#             checkpoint_path_gen = \n",
    "\n",
    "#             checkpoint = torch.load(wandb.restore(CHECKPOINT_PATH))\n",
    "#             model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#             optimizer_generator.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#             epoch = checkpoint['epoch']\n",
    "#             loss = checkpoint['loss']\n",
    "\n",
    "\n",
    "    critic_iter = 0\n",
    "    gen_iter = 0\n",
    "\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(config.epochs):\n",
    "\n",
    "        # set both networks for training mode\n",
    "        generator.train()\n",
    "        critic.train()\n",
    "\n",
    "        # initiate the epoch loss for both networks to zero\n",
    "        batch_nr = 0\n",
    "        epoch_loss_critic = 0.\n",
    "        epoch_loss_generator = 0.\n",
    "        all_loss_critic = 0.\n",
    "\n",
    "        print(f'Epoch: {epoch}')\n",
    "        for batch_idx, (data,labels) in enumerate(trainloader):\n",
    "            step_loss_critic = 0.\n",
    "            batch_nr += 1\n",
    "\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            data = data.float()  #solved error \"Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same\"\n",
    "            count=0\n",
    "            # Train the Critic/Discriminator: max E[critic(real)] - E[critic(fake)]\n",
    "            for _ in range(config.discriminator_updates):\n",
    "                critic_iter = critic_iter +1\n",
    "                count = count+1\n",
    "                noise = torch.randn(config.batch_size,channels_signal,latent_dim).uniform_(-1, 1).to(device)\n",
    "                fake = generator(noise,labels)\n",
    "\n",
    "                critic_real = critic(data,labels).reshape(-1)\n",
    "                critic_fake = critic(fake.detach(),labels).reshape(-1)   #critic(fake,labels).reshape(-1) #here we changed according to github repo alladin, it was before critic_fake = critic(fake.detach(),labels).reshape(-1)\n",
    "\n",
    "                gp = gradient_penalty(critic,labels, data, fake, device = device)\n",
    "                loss_critic =(-(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp)\n",
    "                wandb.log({\"Epoch\":epoch, \"Critic_loss\": loss_critic, \"Critic_iteration\": critic_iter})\n",
    "\n",
    "                step_loss_critic += loss_critic.item()\n",
    "                critic.zero_grad()\n",
    "                loss_critic.backward(retain_graph=True)\n",
    "                optimizer_critic.step()\n",
    "            #all_loss_critic += step_loss_critic/discriminator_updates    \n",
    "           ## clear memory after a no of steps: is it enought to keep the w. for disc_updates steps? ##loss_critic.backward(retain_graph=False)\n",
    "            # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
    "            gen_iter = gen_iter + 1\n",
    "            gen_fake = critic(fake,labels).reshape(-1)\n",
    "            loss_generator = -torch.mean(gen_fake)\n",
    "            #epoch_loss_generator += loss_generator.item()\n",
    "\n",
    "            generator.zero_grad()\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "            wandb.log({\"Epoch\":epoch, \"Generator_iteration\": gen_iter, \"Generator_loss\": loss_generator})   \n",
    "\n",
    "        print(f\"Gen loss:{loss_generator}\")\n",
    "        print(f\"Critic loss::{np.mean(step_loss_critic)}\")   \n",
    "\n",
    "#             # Save model checkpoints\n",
    "#             if (epoch + 1) % 500 == 0:\n",
    "#                 checkpoint_filename_disc = f\"\\disc_APVP_AVD200_epoch{epoch + 1}.pth\"\n",
    "#                 checkpoint_filename_gen = f\"\\gen_APVP_AVD200_epoch{epoch + 1}.pth\"\n",
    "\n",
    "#                 checkpoint_path_disc = wandb.run.dir + checkpoint_filename_disc\n",
    "#                 checkpoint_path_gen = wandb.run.dir + checkpoint_filename_gen\n",
    "\n",
    "#                 torch.save({'epoch': epoch,'model_state_dict': critic.state_dict(),\n",
    "#                             'optimizer_state_dict': optimizer_critic.state_dict(),\n",
    "#                             'loss': config.learning_rate_critic,}, checkpoint_path_disc)\n",
    "#                 wandb.save(checkpoint_path_disc)\n",
    "\n",
    "#                 torch.save({'epoch': epoch,'model_state_dict': generator.state_dict(),\n",
    "#                             'optimizer_state_dict': optimizer_generator.state_dict(),\n",
    "#                             'loss': config.learning_rate_generator,}, checkpoint_path_gen)\n",
    "#                 wandb.save(checkpoint_path_gen)\n",
    "\n",
    "        # Diplay the signals produced by the generator every 100 epochs\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            generator.eval()\n",
    "            with torch.no_grad():\n",
    "                generated_signals = generator(fixed_noise, fixed_labels)\n",
    "                gener = generated_signals.cpu().detach().numpy()\n",
    "\n",
    "                plt.figure(figsize=(8,3))\n",
    "                plt.subplot(311)\n",
    "                plt.title(f'Label: {fixed_labels[0]}')\n",
    "                plt.plot(gener[0][0])\n",
    "                plt.subplot(312)\n",
    "                plt.plot(gener[0][1])\n",
    "                plt.subplot(313)\n",
    "                plt.plot(gener[0][2])\n",
    "\n",
    "                # Log the figure to WandB\n",
    "                wandb.log({'chart': plt})\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eccef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb sync 'Z:\\1938759\\Synhtetic signal simulator\\Our-data\\wandb\\offline-run-20240317_202949-n8y8w3uv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9739cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'Z:\\1938759\\Synhtetic signal simulator\\Our-data\\model_all data'\n",
    "torch.save(generator.state_dict(), os.path.join(PATH,f'{gen_name}.pth'))\n",
    "torch.save(critic.state_dict(), os.path.join(PATH,f'{disc_name}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad71c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b69d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoded values and their original labels:\n",
    "# 0 -> A-tach 2:1 block\n",
    "# 1 -> AF\n",
    "# 2 -> SR\n",
    "# 3 -> SR with LBBB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"  \n",
    "\n",
    "channels_signal = 3\n",
    "num_classes=4\n",
    "embed_size = 800\n",
    "latent_dim = 800\n",
    "generator_layers = 6\n",
    "\n",
    "generator_PATH = r'Z:\\1938759\\Synhtetic signal simulator\\Our-data\\model_all data\\Gen_baseline_all_1000_3C.pth'  # Gen_baseline_all_300_3C\n",
    "generator_loaded = UNet1D(channels_signal, channels_signal, num_classes,embed_size, n_layers = generator_layers).to(device)\n",
    "generator_loaded.load_state_dict(torch.load(generator_PATH))\n",
    "generator_loaded.eval()\n",
    "\n",
    "\n",
    "labels = np.zeros(10)\n",
    "batch_size = len(labels)\n",
    "\n",
    "for j in range(len(labels)):\n",
    "    labels[j] = 2\n",
    "\n",
    "fixed_noise = torch.randn(batch_size,channels_signal,latent_dim).uniform_(-1, 1).to(device)\n",
    "labels =  torch.Tensor(labels).to(device)\n",
    "labels = labels.int()\n",
    "\n",
    "generated_signals = generator_loaded(fixed_noise,labels)\n",
    "gener = generated_signals.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=[10,5])\n",
    "\n",
    "x=0\n",
    "\n",
    "Fs = 1000;  # sampling rate\n",
    "Ts = 1.0/Fs; # sampling interval\n",
    "t = np.arange(0,len(gener[x][0])/Fs,Ts) # time vector\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.title('Synthetic A-tach 2:1 block signals')\n",
    "plt.plot(t,gener[x][0])\n",
    "plt.margins(x=0)\n",
    "plt.ylabel('ECG')\n",
    "\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(t,gener[x][1])\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(t,gener[x][2])\n",
    "\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('ABP')\n",
    "plt.margins(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_beats[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sampling frequency\n",
    "fs = 1000  # Hz\n",
    "\n",
    "# Create a time vector\n",
    "x = 55\n",
    "N = len(signals[x][0])\n",
    "time = np.linspace(0, (N-1)/fs, N)\n",
    "\n",
    "# Creating a grid for subplots: 3 rows, 2 columns\n",
    "fig, ax = plt.subplots(3, 2, figsize=(15, 10))  # Adjusting figure size for better clarity and spacing\n",
    "\n",
    "# Left column plots\n",
    "ax[0, 0].plot(time, signals[x][0])\n",
    "ax[0, 0].set_title('Real Heartbeat', fontname='Arial', fontsize=16)\n",
    "ax[0, 0].set_xlabel('Time (s)', fontname='Arial', fontsize=14)\n",
    "ax[0, 0].set_ylabel('ECG', fontname='Arial', fontsize=14)\n",
    "\n",
    "\n",
    "ax[1, 0].plot(time, signals[x][1])\n",
    "ax[1, 0].set_xlabel('Time (s)', fontname='Arial', fontsize=14)\n",
    "ax[1, 0].set_ylabel('ABP', fontname='Arial', fontsize=14)\n",
    "\n",
    "\n",
    "ax[2, 0].plot(time, signals[x][2])\n",
    "ax[2, 0].set_xlabel('Time (s)', fontname='Arial', fontsize=14)\n",
    "ax[2, 0].set_ylabel('CVP', fontname='Arial', fontsize=14)\n",
    "\n",
    "\n",
    "# Right column plots\n",
    "y = 4\n",
    "ax[0, 1].plot(time, gener[y][0], color='orange')\n",
    "ax[0, 1].set_title('Synthetic Heartbeat', fontname='Arial', fontsize=16)\n",
    "ax[0, 1].set_xlabel('Time (s)', fontname='Arial', fontsize=14)\n",
    "ax[0, 1].set_ylabel('ECG', fontname='Arial', fontsize=14)\n",
    "\n",
    "\n",
    "ax[1, 1].plot(time, gener[y][1], color='orange')\n",
    "ax[1, 1].set_xlabel('Time (s)', fontname='Arial', fontsize=14)\n",
    "ax[1, 1].set_ylabel('ABP', fontname='Arial', fontsize=14)\n",
    "\n",
    "\n",
    "ax[2, 1].plot(time, gener[y][2], color='orange')\n",
    "ax[2, 1].set_xlabel('Time (s)', fontname='Arial', fontsize=14)\n",
    "ax[2, 1].set_ylabel('CVP', fontname='Arial', fontsize=14)\n",
    "\n",
    "fig.tight_layout()  # Automatically adjusts subplot params\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sampling frequency\n",
    "fs = 1000  # Hz\n",
    "\n",
    "# Create a time vector\n",
    "x = 55\n",
    "N = len(signals[x][0])\n",
    "time = np.linspace(0, (N-1)/fs, N)\n",
    "\n",
    "# Creating a grid for subplots: 3 rows, 2 columns\n",
    "fig, ax = plt.subplots(3, 2, figsize=(20, 10))  # Adjusting figure size for better clarity and spacing\n",
    "\n",
    "\n",
    "# Function to setup each axis\n",
    "def setup_axis(ax, data, title, xlabel, ylabel, color='blue'):\n",
    "    ax.plot(time, data, color=color)\n",
    "    ax.set_title(title, fontname='Arial', fontsize=20)\n",
    "    ax.set_xlabel(xlabel, fontname='Arial', fontsize=18)\n",
    "    ax.set_ylabel(ylabel, fontname='Arial', fontsize=18)\n",
    "    ax.margins(x=0)  # Set x-axis margins to zero\n",
    "\n",
    "# Left column plots\n",
    "setup_axis(ax[0, 0], signals[x][0], 'Real Heartbeat', 'Time (s)', 'ECG')\n",
    "setup_axis(ax[1, 0], signals[x][1], '', 'Time (s)', 'ABP')\n",
    "setup_axis(ax[2, 0], signals[x][2], '', 'Time (s)', 'CVP')\n",
    "\n",
    "# Right column plots\n",
    "y = 8  # Example 'y'\n",
    "setup_axis(ax[0, 1], gener[y][0], 'Synthetic Heartbeat', 'Time (s)', 'ECG', color='orange')\n",
    "setup_axis(ax[1, 1], gener[y][1], '', 'Time (s)', 'ABP', color='orange')\n",
    "setup_axis(ax[2, 1], gener[y][2], '', 'Time (s)', 'CVP', color='orange')\n",
    "\n",
    "fig.tight_layout()  # Automatically adjusts subplot params\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5d666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1446f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc51773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from frechetdist import frdist\n",
    "import math\n",
    "import time\n",
    "from dtaidistance import dtw\n",
    "\n",
    "class GANEvaluator:\n",
    "    def __init__(self, real_signals, fake_signals, device):\n",
    "        self.device = device\n",
    "        self.real_signals = [torch.tensor(signal, device=self.device).float() for signal in real_signals]\n",
    "        self.fake_signals = [torch.tensor(signal, device=self.device).float() for signal in fake_signals]\n",
    "        self.time = torch.arange(0, len(self.real_signals[0]), device=self.device) / 360\n",
    "\n",
    "    def shuffle_data(self, data):\n",
    "        random.shuffle(data)\n",
    "\n",
    "    def frechet_distance(self):\n",
    "        frechet_distances = []\n",
    "        for real_points in self.real_signals:\n",
    "            P = torch.stack([self.time, real_points], dim=1).cpu().numpy()\n",
    "            fd = []\n",
    "            for fake_points in self.fake_signals:\n",
    "                Q = torch.stack([self.time, fake_points], dim=1).cpu().numpy()\n",
    "                fd.append(frdist(P, Q))\n",
    "            frechet_distances.append(min(fd))\n",
    "        return np.mean(frechet_distances)\n",
    "\n",
    "    def calculate_metric(self, metric_func):\n",
    "        metrics = []\n",
    "        for real_points in self.real_signals:\n",
    "            tmp_metrics = []\n",
    "            for fake_points in self.fake_signals:\n",
    "                if len(real_points) != len(fake_points):\n",
    "                    raise ValueError(\"Both lists of signals must have the same length.\")\n",
    "                tmp_metrics.append(metric_func(real_points, fake_points).item())\n",
    "            metrics.append(min(tmp_metrics))\n",
    "        return np.mean(metrics)\n",
    "\n",
    "    def MSE(self, real, fake):\n",
    "        return (real - fake).pow(2).mean()\n",
    "\n",
    "    def RMSE(self, real, fake):\n",
    "        return torch.sqrt((real - fake).pow(2).mean())\n",
    "\n",
    "    def MAE(self, real, fake):\n",
    "        return torch.abs(real - fake).mean()\n",
    "\n",
    "    def calculate_prmse(self):\n",
    "        prmse_values = []\n",
    "        for real_points in self.real_signals:\n",
    "            max_real_value = torch.max(real_points)\n",
    "            tmp_squared_errors = []\n",
    "            for fake_points in self.fake_signals:\n",
    "                rmse = torch.sqrt(((real_points - fake_points) ** 2).mean()).item()\n",
    "                tmp_squared_errors.append(rmse ** 2)\n",
    "            min_squared_error = min(tmp_squared_errors)\n",
    "            prmse_percentage = (np.sqrt(min_squared_error) / max_real_value.item()) * 100\n",
    "            prmse_values.append(prmse_percentage)\n",
    "        return np.mean(prmse_values)\n",
    "\n",
    "#     # DTW calculation method\n",
    "#     def DTW(self, real, fake):\n",
    "#         n, m = len(real), len(fake)\n",
    "#         dtw_matrix = np.full((n+1, m+1), np.inf)\n",
    "#         dtw_matrix[0, 0] = 0\n",
    "\n",
    "#         for i in range(1, n+1):\n",
    "#             for j in range(1, m+1):\n",
    "#                 cost = abs(real[i-1] - fake[j-1])\n",
    "#                 dtw_matrix[i, j] = cost + min(dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1])\n",
    "\n",
    "#         return dtw_matrix[n, m]\n",
    "\n",
    "#     # Method to calculate DTW for all real-fake pairs and return the average\n",
    "#     def calculate_dtw_distance(self):\n",
    "#         dtw_distances = []\n",
    "#         for real_signal in self.real_signals:\n",
    "#             dtw_per_real = []\n",
    "#             for fake_signal in self.fake_signals:\n",
    "#                 dtw_per_real.append(self.DTW(real_signal.cpu().numpy(), fake_signal.cpu().numpy()))\n",
    "#             dtw_distances.append(min(dtw_per_real))\n",
    "#         return np.mean(dtw_distances)\n",
    "\n",
    "    def gaussian_kernel(self, X, Y, sigma=1.0):\n",
    "        XX = torch.matmul(X, X.T)\n",
    "        XY = torch.matmul(X, Y.T)\n",
    "        YY = torch.matmul(Y, Y.T)\n",
    "        X_sqnorms = torch.diagonal(XX)\n",
    "        Y_sqnorms = torch.diagonal(YY)\n",
    "        \n",
    "        K = torch.exp(-0.5 * (X_sqnorms[:, None] + Y_sqnorms[None, :] - 2 * XY) / sigma**2)\n",
    "        return K\n",
    "    \n",
    "    def mmd(self, sigma=1.0):\n",
    "        mmd_distances = []\n",
    "        for real_points in self.real_signals:\n",
    "            P = real_points.unsqueeze(1)\n",
    "            mmd_values = []\n",
    "            for fake_points in self.fake_signals:\n",
    "                Q = fake_points.unsqueeze(1)\n",
    "                \n",
    "                K_PP = self.gaussian_kernel(P, P, sigma)\n",
    "                K_QQ = self.gaussian_kernel(Q, Q, sigma)\n",
    "                K_PQ = self.gaussian_kernel(P, Q, sigma)\n",
    "                \n",
    "                mmd_value = K_PP.mean() + K_QQ.mean() - 2 * K_PQ.mean()\n",
    "                mmd_values.append(mmd_value.item())\n",
    "            mmd_distances.append(min(mmd_values))\n",
    "        return np.mean(mmd_distances)\n",
    "    \n",
    "    def dtw_distance(self):\n",
    "        dtw_distances = []\n",
    "        for real_signal in self.real_signals:\n",
    "            real_signal = real_signal.cpu().numpy()\n",
    "            dtw_per_real = []\n",
    "            for fake_signal in self.fake_signals:\n",
    "                fake_signal = fake_signal.cpu().numpy()\n",
    "                if real_signal.ndim == 1 and fake_signal.ndim == 1:\n",
    "                    # Univariate case\n",
    "                    distance = dtw.distance(real_signal, fake_signal)\n",
    "                    dtw_per_real.append(distance)\n",
    "                elif real_signal.ndim == 2 and fake_signal.ndim == 2:\n",
    "                    # Multivariate case: compute DTW for each dimension and take the average\n",
    "                    distances = [dtw.distance(real_signal[:, i], fake_signal[:, i]) for i in range(real_signal.shape[1])]\n",
    "                    distance = np.mean(distances)\n",
    "                    dtw_per_real.append(distance)\n",
    "                else:\n",
    "                    raise ValueError(\"Mismatched dimensions between real and fake signals\")\n",
    "            if dtw_per_real:\n",
    "                dtw_distances.append(min(dtw_per_real))\n",
    "        if dtw_distances:\n",
    "            return np.mean(dtw_distances)\n",
    "        else:\n",
    "            return float('inf')  # or some other appropriate value for no signals\n",
    "\n",
    "    \n",
    "def evaluate_all(path, generated_samples):\n",
    "    \n",
    "    signal_labels_numeric = list(np.unique(enc_data, return_counts=False))\n",
    "    signal_labels_real = list(np.unique(labels_beats, return_counts=False))\n",
    "    \n",
    "    device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"  \n",
    "    \n",
    "    channels_signal = 3\n",
    "    num_classes=4\n",
    "    embed_size = 800\n",
    "    latent_dim = 800\n",
    "    generator_layers = 6\n",
    "\n",
    "    generator_PATH = r'Z:\\1938759\\Synhtetic signal simulator\\Our-data\\model_all data\\Gen_baseline_all_1000_3C.pth'  # Gen_baseline_all_300_3C\n",
    "    generator_loaded = UNet1D(channels_signal, channels_signal, num_classes,embed_size, n_layers = generator_layers).to(device)\n",
    "    generator_loaded.load_state_dict(torch.load(generator_PATH))\n",
    "    generator_loaded.eval()\n",
    "\n",
    "    for i in range(len(signal_labels_numeric)):\n",
    "        labels = np.zeros(generated_samples)\n",
    "        batch_size = len(labels)\n",
    "        \n",
    "        for j in range(len(labels)):\n",
    "            labels[j] = signal_labels_numeric[i] \n",
    "\n",
    "        fixed_noise = torch.randn(batch_size,channels_signal,latent_dim).uniform_(-1, 1).to(device)\n",
    "        labels =  torch.Tensor(labels).to(device)\n",
    "        labels = labels.int()\n",
    "\n",
    "        generated_signals = generator_loaded(fixed_noise,labels)\n",
    "        gener = generated_signals.cpu().detach().numpy()\n",
    "        \n",
    "        # Identify the heartbeats/signals that have the label the same as the selected label from the list\n",
    "        real_beats = []\n",
    "        for k in range(0,len(labels_beats)):\n",
    "            if labels_beats[k] == signal_labels_real[i]:\n",
    "                real_beats.append(i)\n",
    "\n",
    "        real_beats = [np.array(signals[i]) for i in real_beats]\n",
    "        #real_beats =  np.array(real_beats).reshape((len(real_beats), 1, 800))\n",
    "        random_selected = random.sample(list(real_beats), generated_samples)\n",
    "        \n",
    "        list_sig_type = ['ECG', 'ABP', 'CVP']\n",
    "        \n",
    "        for k in range(np.shape(real_beats)[1]):\n",
    "            orig_signal_type = [random_selected[i][k] for i in range(len(random_selected))]\n",
    "            gener_signal_type = [gener[i][k] for i in range(len(gener))]\n",
    "        \n",
    "            print(f'The signal evaluated is: {list_sig_type[k]}')\n",
    "            print(f'The class evaluated is: {signal_labels_real[i]}')\n",
    "            \n",
    "            # Prepare the data \n",
    "#             original_data = np.squeeze(np.array(orig_signal_type), axis=1)\n",
    "#             generated_data = np.squeeze(np.array(gener_signal_type), axis=1)\n",
    "\n",
    "            # Instantiate the GANEvaluator class\n",
    "            gan_evaluator = GANEvaluator(orig_signal_type, gener_signal_type, device)\n",
    "\n",
    "            # Call each function on the instance and # Print the results\n",
    "            gan_evaluator.shuffle_data(orig_signal_type)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            mse_value = gan_evaluator.calculate_metric(gan_evaluator.MSE)\n",
    "            print(f'MSE value for ECG signals is: {mse_value}')\n",
    "            rmse_value = gan_evaluator.calculate_metric(gan_evaluator.RMSE)\n",
    "            print(f'RMSE value for ECG signal is: {rmse_value}')\n",
    "            mae_value = gan_evaluator.calculate_metric(gan_evaluator.MAE)\n",
    "            print(f'MAE value for ECG signals is: {mae_value}')\n",
    "            prmse_value = gan_evaluator.calculate_prmse()\n",
    "            print(f'PRMSE value for ECG signals is: {prmse_value}')\n",
    "            dtw_distance = gan_evaluator.calculate_dtw_distance()\n",
    "            print(f'DTW value for ECG signals is: {dtw_distance}')\n",
    "            frechet_dist_value = gan_evaluator.frechet_distance()\n",
    "            print(f'Frechet Distance value: {frechet_dist_value}')\n",
    "            \n",
    "            dtw_value = gan_evaluator.dtw_distance()\n",
    "            print(f'DTW value: {dtw_value}')\n",
    "            \n",
    "            mmd_value = gan_evaluator.mmd(sigma=1.0)\n",
    "            print(f'MMD value: {mmd_value}')  \n",
    "            \n",
    "            Record the end time\n",
    "            end_time = time.time()\n",
    "\n",
    "            Calculate and print the elapsed time\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(f\"The code took {elapsed_time} seconds to run.\")\n",
    "            print(f\"The code took {elapsed_time/3600} hours to run.\")\n",
    "\n",
    "            print('________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b50e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_all(_, 400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
