{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class CNN_Discriminator(nn.Module):\n",
    "    # Code copied from https://github.com/vlbthambawita/deepfake-ecg/blob/9fa9a02a9fefe579e322d56fa591c3887d7ad135/deepfakeecg/models/pulse2pulse.py#L5\n",
    "   \n",
    "    def __init__(self, num_classes, signal_length, model_size=64, ngpus=1, num_channels=2, shift_factor=2,\n",
    "                 alpha=0.2, verbose=False, dropout=None):\n",
    "        super(CNN_Discriminator, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.signal_length = signal_length\n",
    "        self.model_size = model_size  # d\n",
    "        self.ngpus = ngpus\n",
    "        self.num_channels = num_channels  # c\n",
    "        self.shift_factor = shift_factor  # n\n",
    "        self.alpha = alpha\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.embed = nn.Embedding(num_classes, 1*signal_length)\n",
    "        self.conv1 = nn.Conv1d(num_channels+1,  model_size, 5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(model_size, 2 * model_size, 5, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(2 * model_size, 5 * model_size, 5, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv1d(5 * model_size, 10 * model_size, 5, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv1d(10 * model_size, 20 * model_size, 5, stride=2, padding=1)\n",
    "        self.conv6 = nn.Conv1d(20 * model_size, 25 * model_size, 5, stride=4, padding=1)\n",
    "        #self.conv7 = nn.Conv1d(25 * model_size, 100 * model_size, 5, stride=4, padding=1)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.fc1 = nn.Linear(9600, 1) #9600\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "#                 nn.init.kaiming_normal_(m.weight.data)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        #print(x.shape)\n",
    "        embedding = self.embed(labels).view(labels.shape[0], 1,self.signal_length) \n",
    "        #print(embedding.shape)\n",
    "        x = torch.cat([x,embedding], dim=1) # N x C x channel_signal x signal_length\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, self.dropout)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, self.dropout)\n",
    "            \n",
    "        x = F.leaky_relu(self.conv3(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, self.dropout)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, self.dropout)\n",
    "            \n",
    "        x = F.leaky_relu(self.conv5(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        #x = self.ps5(x)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, self.dropout)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv6(x), negative_slope=self.alpha)\n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, self.dropout)\n",
    "\n",
    "        x = x.view(-1, x.shape[1] * x.shape[2])\n",
    "  \n",
    "        if self.verbose:\n",
    "            print(x.shape)\n",
    "    \n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5ceed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, 3, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, 3, padding=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class InConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(InConv, self).__init__()\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, dropout=None):\n",
    "        super(Down, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.maxpool = nn.MaxPool1d(2)\n",
    "        self.dbc = DoubleConv(in_ch, out_ch)\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dbc(x)\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, self.dropout)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Up, self).__init__()\n",
    "        self.up = nn.ConvTranspose1d(in_ch // 2, in_ch // 2, 2, stride=2)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diff = x2.size()[2] - x1.size()[2]\n",
    "        x1 = F.pad(x1, (diff // 2, diff - diff // 2))\n",
    "        # for padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1) # dim=1 because we add them on channel dimension \n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_classes, embed_size, n_layers, ngpus=1, starting_layers=32, dropout=None):\n",
    "        super(UNet1D, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.n_layers = n_layers\n",
    "        self.inc = InConv(in_channels+1, starting_layers)\n",
    "        self.down1 = Down(starting_layers * 1, starting_layers * 2, dropout)  # Only dropout on early layers\n",
    "        self.down2 = Down(starting_layers * 2, starting_layers * 4, dropout)\n",
    "        self.down3 = Down(starting_layers * 4, starting_layers * 8, dropout)\n",
    "        self.down4 = Down(starting_layers * 8, starting_layers * 8, dropout)\n",
    "        if self.n_layers >= 5:\n",
    "            self.down5 = Down(starting_layers * 8, starting_layers * 8)\n",
    "            if self.n_layers >= 6:\n",
    "                self.down6 = Down(starting_layers * 8, starting_layers * 8)\n",
    "                self.up6 = Up(starting_layers * 16, starting_layers * 8)\n",
    "            self.up5 = Up(starting_layers * 16, starting_layers * 8)\n",
    "        self.up4 = Up(starting_layers * 16, starting_layers * 4)\n",
    "        self.up3 = Up(starting_layers * 8, starting_layers * 2)\n",
    "        self.up2 = Up(starting_layers * 4, starting_layers)\n",
    "        self.up1 = Up(starting_layers * 2, starting_layers)\n",
    "        self.out = OutConv(starting_layers, out_channels)\n",
    "        self.embed = nn.Embedding(num_classes, embed_size)\n",
    "        \n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.ConvTranspose1d) or isinstance(m, nn.Linear):\n",
    "#                 nn.init.kaiming_normal_(m.weight.data)\n",
    "    def forward(self, x,labels):\n",
    "        embedding = self.embed(labels).unsqueeze(1)#.unsqueeze(3) # adds 1 x 1 at the end\n",
    "        x = torch.cat([x, embedding],dim=1)\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "\n",
    "        if self.n_layers >= 4:\n",
    "            x5 = self.down4(x4)\n",
    "            x = x5\n",
    "            if self.n_layers >= 5:\n",
    "                x6 = self.down5(x5)\n",
    "                x = x6\n",
    "                if self.n_layers >= 6:\n",
    "                    x7 = self.down6(x6)\n",
    "                    x = x7\n",
    "                    x = self.up6(x, x6)\n",
    "                x = self.up5(x, x5)\n",
    "            x = self.up4(x, x4)\n",
    "        x = self.up3(x, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up1(x, x1)\n",
    "        x = torch.tanh(self.out(x))\n",
    "   \n",
    "        # latent vector z: N x noise_dim x 1 x 1\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "affc29be",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 750])\n",
      "torch.Size([1, 3, 750])\n",
      "torch.Size([1, 3, 750])\n",
      "torch.Size([1, 128, 93])\n",
      "torch.Size([1, 64, 187])\n",
      "torch.Size([1, 32, 375])\n",
      "torch.Size([1, 2, 750])\n"
     ]
    }
   ],
   "source": [
    "# from torchvision import models\n",
    "# from torchsummary import summary\n",
    "\n",
    "# num_classes = 4\n",
    "# embed_size = 750\n",
    "# signal_length = 750\n",
    "\n",
    "# device = \"cpu\"\n",
    "# generator = UNet1D(2, 2, 4,750, n_layers=5).to(device)\n",
    "\n",
    "# labels2 = [2 for i in range(1)]\n",
    "\n",
    "# batch_size = len(labels2)\n",
    "# fixed_noise = torch.randn(batch_size,2,750).uniform_(-1, 1).to(device)\n",
    "# labels2 =  torch.Tensor(labels2).to(device)\n",
    "# labels2 = labels2.int()\n",
    "# #labels2 = labels2.to(device)\n",
    "# #generator.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     generated_signals = generator(fixed_noise,labels2)\n",
    "#     gener = generated_signals.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416becb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv1d, nn.ConvTranspose1d, nn.Linear)):\n",
    "            #nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "            nn.init.kaiming_normal_(m.weight.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
